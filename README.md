# üå±‚ö° EcoSmart Insights

**Plateforme d'analyse et pr√©diction de la consommation √©nerg√©tique domestique utilisant le Data Mining**

Application web full-stack qui permet d'analyser, pr√©dire et optimiser la consommation √©nerg√©tique gr√¢ce √† des algorithmes de Machine Learning avanc√©s.

![Python](https://img.shields.io/badge/Python-3.11-blue)
![React](https://img.shields.io/badge/React-18.2-blue)
![Flask](https://img.shields.io/badge/Flask-3.0-green)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3-orange)
![License](https://img.shields.io/badge/License-MIT-yellow)

---

## üìã Table des Mati√®res

- [Pr√©sentation](#-pr√©sentation)
- [Fonctionnalit√©s](#-fonctionnalit√©s)
- [Algorithmes de Data Mining](#-algorithmes-de-data-mining)
- [Technologies Utilis√©es](#-technologies-utilis√©es)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Structure du Projet](#-structure-du-projet)
- [Captures d'√âcran](#-captures-d√©cran)
- [API Endpoints](#-api-endpoints)

---

## üéØ Pr√©sentation

EcoSmart Insights est une application web intelligente d√©velopp√©e dans le cadre du **Mini-Projet Data Mining (3DNI - 2025)** qui permet aux utilisateurs de :

- üìä **Analyser** leur consommation √©nerg√©tique d√©taill√©e
- üîÆ **Pr√©dire** leur consommation future sur 7 jours
- üéØ **Classifier** leur profil de consommation (√âconome, Moyen, √âlev√©, Irr√©gulier)
- ‚ö†Ô∏è **D√©tecter** les anomalies et pics inhabituels
- üí° **Recevoir** des recommandations personnalis√©es d'√©conomie d'√©nergie

---

## ‚ú® Fonctionnalit√©s

### 1. Upload et Validation de Donn√©es
- Import de fichiers CSV avec validation automatique
- G√©n√©ration de donn√©es d'exemple pour d√©monstration
- Support du drag & drop

### 2. Analyse de Profil (Classification)
- Classification automatique en 4 profils de consommation
- Comparaison avec les moyennes nationales
- Analyse des caract√©ristiques de consommation

### 3. D√©tection d'Anomalies (Isolation Forest)
- Identification des pics de consommation inhabituels
- Calcul des √©carts en pourcentage
- Suggestions de causes probables

### 4. Analyse des Patterns Temporels
- Graphiques de consommation horaire
- Identification des heures de pointe
- Recommandations d'heures creuses

### 5. Pr√©dictions (Random Forest)
- Pr√©diction sur 7 jours avec granularit√© horaire
- Estimation des co√ªts futurs
- Graphiques de tendances

### 6. Recommandations Personnalis√©es
- Conseils adapt√©s au profil utilisateur
- Estimation des √©conomies potentielles
- Priorisation des actions (Haute/Moyenne/Basse)

---

## üß† Algorithmes de Data Mining

### 1. **Classification Bas√©e sur R√®gles**
```python
# Profil de consommation bas√© sur la moyenne et variance
if avg_consumption < 4.0:
    profil = "√âconome"
elif avg_consumption < 6.0:
    profil = "Moyen"
elif std_consumption < 2.0:
    profil = "√âlev√©"
else:
    profil = "Irr√©gulier"
```

### 2. **Isolation Forest** (D√©tection d'Anomalies)
```python
IsolationForest(
    contamination=0.05,  # 5% d'anomalies attendues
    random_state=42
)
```

### 3. **Random Forest Regressor** (Pr√©diction)
```python
RandomForestRegressor(
    n_estimators=50,
    max_depth=10,
    random_state=42
)
```

### 4. **Analyse de S√©ries Temporelles**
- Moyenne mobile sur 24h
- D√©tection de patterns horaires et hebdomadaires
- Feature engineering temporel

---

## üõ†Ô∏è Technologies Utilis√©es

### Backend
- **Flask 3.0** - Framework web Python
- **Pandas 2.1** - Manipulation de donn√©es
- **Scikit-learn 1.3** - Algorithmes de Machine Learning
- **NumPy 1.26** - Calculs num√©riques

### Frontend
- **React 18.2** - Interface utilisateur
- **Vite 5.0** - Build tool rapide
- **Tailwind CSS 3.4** - Framework CSS
- **Recharts 2.10** - Visualisations de donn√©es
- **Axios 1.6** - Requ√™tes HTTP

### Data Mining
- **Classification** - Profiling utilisateur
- **Isolation Forest** - D√©tection d'anomalies
- **Random Forest** - Pr√©diction de s√©ries temporelles
- **Feature Engineering** - Extraction de caract√©ristiques temporelles

---

## üöÄ Installation

### Pr√©requis

- **Python 3.11+** install√©
- **Node.js 18+** et npm install√©s
- **Git** install√©

### 1. Cloner le Repository
```bash
git clone https://github.com/votre-username/ecosmart-insights.git
cd ecosmart-insights
```

### 2. Installation du Backend
```bash
# Aller dans le dossier backend
cd backend

# Cr√©er un environnement virtuel
python -m venv venv

# Activer l'environnement virtuel
# Windows
.\venv\Scripts\activate
# Linux/Mac
source venv/bin/activate

# Installer les d√©pendances
pip install -r requirements.txt
```

### 3. Installation du Frontend
```bash
# Aller dans le dossier frontend
cd ../frontend

# Installer les d√©pendances
npm install
```

---

## üíª Utilisation

### D√©marrer le Backend
```bash
# Dans le dossier backend avec venv activ√©
cd backend
.\venv\Scripts\activate  # Windows
python app.py
```

Le backend sera accessible sur **http://localhost:5000**

### D√©marrer le Frontend
```bash
# Dans un nouveau terminal, dossier frontend
cd frontend
npm run dev
```

Le frontend sera accessible sur **http://localhost:5173**

### Utiliser l'Application

1. **Ouvrir** http://localhost:5173 dans votre navigateur
2. **Cliquer** sur "Donn√©es d'exemple" pour tester rapidement
3. **OU** uploader votre propre fichier CSV au format :
```csv
timestamp,consumption_kwh
2024-01-01 00:00:00,2.3
2024-01-01 01:00:00,1.8
2024-01-01 02:00:00,1.6
...
```

4. **Explorer** le dashboard avec toutes les analyses

---

## üìÅ Structure du Projet
```
ecosmart-insights/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_mining.py          # Algorithmes ML
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py        # Traitement des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generate_sample_data.py # G√©n√©ration de donn√©es test
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ helpers.py              # Fonctions utilitaires
‚îÇ   ‚îú‚îÄ‚îÄ uploads/                     # Fichiers upload√©s (gitignore)
‚îÇ   ‚îú‚îÄ‚îÄ app.py                       # Application Flask principale
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt             # D√©pendances Python
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FileUpload.jsx      # Upload de fichiers
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dashboard.jsx       # Tableau de bord principal
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ClusterProfile.jsx  # Affichage du profil
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AnomaliesChart.jsx  # Graphique anomalies
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Analytics.jsx       # Graphiques d'analyse
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Predictions.jsx     # Pr√©dictions futures
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Recommendations.jsx # Recommandations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.js              # Services API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ helpers.js          # Utilitaires
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx                 # Composant principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.jsx                # Point d'entr√©e
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.css               # Styles globaux
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ tailwind.config.js
‚îÇ   ‚îî‚îÄ‚îÄ vite.config.js
‚îÇ
‚îî‚îÄ‚îÄ README.md
```

---

## üì∏ DEMO

### D√©mo de projet
![DEMO](screenshots/DEMO.gif)



---

## üîå API Endpoints

### Backend API (Port 5000)

| M√©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/` | Informations API |
| GET | `/api/health` | Health check |
| POST | `/api/upload` | Upload fichier CSV |
| POST | `/api/analyze` | Analyse compl√®te des donn√©es |
| POST | `/api/predict` | Pr√©diction future (7 jours) |
| POST | `/api/recommendations` | Recommandations personnalis√©es |
| GET | `/api/generate-sample` | G√©n√©rer donn√©es d'exemple |

### Exemple de Requ√™te
```javascript
// Analyser des donn√©es
fetch('http://localhost:5000/api/analyze', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ 
    filepath: 'uploads/data.csv' 
  })
})
```

---

## üß™ Tests

### Tester le Backend
```bash
# Test manuel de l'API
curl http://localhost:5000/api/health

# G√©n√©rer des donn√©es de test
curl http://localhost:5000/api/generate-sample?days=30
```

### Tester le Frontend
```bash
# Dans le dossier frontend
npm run dev
```

Ouvrir http://localhost:5173 et cliquer sur "Donn√©es d'exemple"

---

## üìä Format des Donn√©es

### Fichier CSV d'Entr√©e

Le fichier CSV doit contenir deux colonnes :

- `timestamp` : Date et heure au format `YYYY-MM-DD HH:MM:SS`
- `consumption_kwh` : Consommation en kWh (nombre d√©cimal)

**Exemple :**
```csv
timestamp,consumption_kwh
2024-12-01 00:00:00,2.1
2024-12-01 01:00:00,1.8
2024-12-01 02:00:00,1.6
```

**Minimum requis :** 48 heures de donn√©es (2 jours)

---

## üéì Projet Acad√©mique

**Cadre :** Mini-Projet Data Mining - 3DNI 2025  
**Universit√© :** [ISITCOM]  
**Module :** Data Mining  
**Date :** D√©cembre 2025

### Objectifs P√©dagogiques

‚úÖ Impl√©mentation d'algorithmes de Data Mining  
‚úÖ D√©veloppement d'une application full-stack  
‚úÖ Traitement et visualisation de donn√©es  
‚úÖ Application pratique du Machine Learning  

---

## üë• Auteurs

- **[ASMA DAOUSSI]** 
- **[ONS TOUKA]** 



---

## üôè Remerciements

- **Enseignants du module Data Mining** pour leurs conseils
- **Scikit-learn** pour les algorithmes de ML
- **React & Flask communities** pour la documentation


---

## üöÄ Am√©liorations Futures

- [ ] Support de multiples formats de fichiers (Excel, JSON)
- [ ] Export des rapports en PDF
- [ ] Comparaison de plusieurs p√©riodes
- [ ] Notifications en temps r√©el
- [ ] Application mobile
- [ ] Int√©gration avec compteurs intelligents

---

**‚≠ê Si ce projet vous a √©t√© utile, n'oubliez pas de lui donner une √©toile !**

---

Made with ‚ù§Ô∏è by [ASMA DAOUSSI ET ONS TOUKA] | ¬© 2025